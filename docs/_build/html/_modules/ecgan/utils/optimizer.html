

<!DOCTYPE html>
<html class="writer-html5" lang="Python" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>ecgan.utils.optimizer &mdash; ECGAN 1.0.0 documentation</title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="author" title="About these documents" href="../../../about.html" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> ECGAN
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../get_started.html">Get started</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../get_started.html#setup-and-first-steps">Setup and first steps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../get_started.html#setting-up-tracking-w-b">Setting up tracking (W&amp;B)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../get_started.html#setting-up-kaggle-optional">Setting up kaggle [Optional]</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../get_started.html#setting-up-s3-boto">Setting up S3/BOTO</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../structure.html">Framework Structure</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../structure.html#general-overview">General overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../structure.html#run-models-using-the-cli">Run models using the CLI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../structure.html#managing-the-workflow">Managing the workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../structure.html#implement-your-own-usecase">Implement Your Own Usecase</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../supported.html">Supported Methods and Datasets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../supported.html#supported-datasets">Supported Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../supported.html#supported-preprocessing">Supported Preprocessing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../supported.html#supported-training">Supported Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../supported.html#supported-models">Supported Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../supported.html#supported-trackers">Supported trackers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../supported.html#further-downstream-tasks">Further downstream tasks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../preprocessing.html">Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../synthesis.html">Data Synthesis</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../synthesis.html#beatgan">BeatGAN</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../anomaly_detection.html">Anomaly Detection</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../anomaly_detection.html#anogan">AnoGAN</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../classification.html">Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/index.html">Python API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/cli.html">CLI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/manager.html">Manager</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/config/index.html">Config</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/config/dataclasses.html">Custom Dataclasses</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/config/global_configs.html">Global configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/config/initialization.html">Config initializations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/config/nested_dataclasses.html">Nested Dataclasses</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/preprocessing/index.html">Preprocessing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/preprocessing/cleansing.html">Cleansing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/preprocessing/data_retrieval.html">Data Retrieval</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/preprocessing/preprocessor.html">Preprocessor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/preprocessing/sampling.html">Sampling</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/training/index.html">Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/training/datasets.html">Dataset Structures</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/training/trainer.html">Trainer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/modules/index.html">Modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/modules/basemodule.html">Base Module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/modules/generative/index.html">Generative Modules</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/modules/generative/base.html">Generative Base Modules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/modules/generative/beatgan.html">Autoencoder GAN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/modules/generative/dcgan.html">DCGAN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/modules/generative/ecgan.html">Recurrent DCGAN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/modules/generative/rgan.html">RGAN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/modules/generative/vaegan.html">VAEGAN</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/modules/classifiers/index.html">Classification Modules</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/modules/classifiers/base.html">Base classifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/modules/classifiers/nn_classifier.html">NN Classifier</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/modules/inverse_mapping/index.html">Inverse Mappings</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/modules/inverse_mapping/inverse_mapping.html">Inverse Mapping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/modules/inverse_mapping/inversion.html">Base Inverse Mapping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/modules/inverse_mapping/vanilla_inverse_mapping.html">Simple Inverse Mapping</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/networks/index.html">Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/anomaly_detection/index.html">Anomaly Detection</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/anomaly_detection/anomaly_assessment.html">Anomaly Assessment</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/anomaly_detection/anomaly_manager.html">Anomaly Manager</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/anomaly_detection/embedder.html">Embedders</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/anomaly_detection/reconstruction.html">Reconstruction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/anomaly_detection/detector/index.html">Detectors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/anomaly_detection/detector/base_detector.html">Base Detector</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/anomaly_detection/detector/classification_detector.html">Classification Detector</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/anomaly_detection/detector/detector_factory.html">Detector Factory</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/anomaly_detection/detector/reconstruction_detector.html">Reconstruction Detector</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/evaluation/index.html">Evaluation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/evaluation/metrics.html">Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/evaluation/optimization.html">Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/evaluation/tracker.html">Tracker</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/visualization/index.html">Visualization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/visualization/evaluation.html">Evaluation visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/visualization/plotter.html">Plotter</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/utils/index.html">Utils</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/artifacts.html">Tracking artifacts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/configurable.html">Configurable</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/custom_types.html">Custom Types</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/datasets.html">Datasets</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/utils/datasets.html#role-in-the-ecgan-pipeline">Role in the ECGAN Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/utils/datasets.html#adding-new-datasets">Adding new Datasets</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/distances.html">Distances</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/distributions.html">Custom distributions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/embeddings.html">Embeddings</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/interpolation.html">Interpolation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/label.html">Label</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/layers.html">Layers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/log.html">Logging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/losses.html">Loss functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/miscellaneous.html">Miscellaneous</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/optimizer.html">Optimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/parser.html">Parser options for the CLI commands</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/plotting.html">Plotting helpers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/reconstruction_criteria.html">Reconstruction Criteria</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/sampler.html">Sampler</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/splitting.html">Splitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/timer.html">Timer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/utils/transformation.html">Transformation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../references.html">References</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../references.html#related-work">Related Work</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../references.html#data">Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../references.html#related-modules">Related Modules</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../about.html">About</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../about.html#goal">Goal</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../about.html#contributing">Contributing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../about.html#get-started-with-the-development">Get started with the development</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../about.html#improving-baselines">Improving Baselines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../about.html#adding-modules">Adding Modules</a></li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">ECGAN</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>ecgan.utils.optimizer</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for ecgan.utils.optimizer</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Wrapper class for supported optimizer functions.&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">logging</span> <span class="kn">import</span> <span class="n">getLogger</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch.optim</span>
<span class="kn">from</span> <span class="nn">adabelief_pytorch</span> <span class="kn">import</span> <span class="n">AdaBelief</span> <span class="k">as</span> <span class="n">AdaBeliefOptimizer</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>

<span class="kn">from</span> <span class="nn">ecgan.config</span> <span class="kn">import</span> <span class="n">OptimizerConfig</span><span class="p">,</span> <span class="n">get_</span>
<span class="kn">from</span> <span class="nn">ecgan.utils.configurable</span> <span class="kn">import</span> <span class="n">Configurable</span>
<span class="kn">from</span> <span class="nn">ecgan.utils.custom_types</span> <span class="kn">import</span> <span class="n">Optimizers</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="BaseOptimizer"><a class="viewcode-back" href="../../../api/utils/optimizer.html#ecgan.utils.optimizer.BaseOptimizer">[docs]</a><span class="k">class</span> <span class="nc">BaseOptimizer</span><span class="p">(</span><span class="n">Configurable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Base optimizer class for custom optimizers.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module_config</span><span class="p">,</span> <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span> <span class="o">=</span> <span class="n">weight_decay</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span> <span class="o">=</span> <span class="n">module_config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_group</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

<div class="viewcode-block" id="BaseOptimizer.optimize"><a class="viewcode-back" href="../../../api/utils/optimizer.html#ecgan.utils.optimizer.BaseOptimizer.optimize">[docs]</a>    <span class="k">def</span> <span class="nf">optimize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">losses</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]]]):</span>
        <span class="sd">&quot;&quot;&quot;Perform an optimization step given zero, one or several losses.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">List</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="ow">in</span> <span class="n">losses</span><span class="p">:</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">losses</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">()</span></div>

    <span class="nd">@property</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the PyTorch optimizer used for the optimization.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Optimizer needs to implement the `_optimizer` method.&quot;</span><span class="p">)</span>

<div class="viewcode-block" id="BaseOptimizer.state_dict"><a class="viewcode-back" href="../../../api/utils/optimizer.html#ecgan.utils.optimizer.BaseOptimizer.state_dict">[docs]</a>    <span class="k">def</span> <span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the state dict of the PyTorch optimizer.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>  <span class="c1"># type: ignore</span></div>

<div class="viewcode-block" id="BaseOptimizer.zero_grad"><a class="viewcode-back" href="../../../api/utils/optimizer.html#ecgan.utils.optimizer.BaseOptimizer.zero_grad">[docs]</a>    <span class="k">def</span> <span class="nf">zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Zero the gradient of the optimizer.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span></div>

<div class="viewcode-block" id="BaseOptimizer.step"><a class="viewcode-back" href="../../../api/utils/optimizer.html#ecgan.utils.optimizer.BaseOptimizer.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Perform an optimizer step.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span></div>

<div class="viewcode-block" id="BaseOptimizer.set_param_group"><a class="viewcode-back" href="../../../api/utils/optimizer.html#ecgan.utils.optimizer.BaseOptimizer.set_param_group">[docs]</a>    <span class="k">def</span> <span class="nf">set_param_group</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">updated_lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set optimizer params for adaptive LR.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">group</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">updated_lr</span></div>

<div class="viewcode-block" id="BaseOptimizer.load_existing_optim"><a class="viewcode-back" href="../../../api/utils/optimizer.html#ecgan.utils.optimizer.BaseOptimizer.load_existing_optim">[docs]</a>    <span class="k">def</span> <span class="nf">load_existing_optim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Load an already trained optim from an existing state_dict.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span></div>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_configure</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;OPTIMIZER&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;NAME&#39;</span><span class="p">:</span> <span class="n">name</span><span class="p">,</span> <span class="s1">&#39;LR&#39;</span><span class="p">:</span> <span class="n">lr</span><span class="p">,</span> <span class="s1">&#39;WEIGHT_DECAY&#39;</span><span class="p">:</span> <span class="n">weight_decay</span><span class="p">}}</span>

<div class="viewcode-block" id="BaseOptimizer.configure"><a class="viewcode-back" href="../../../api/utils/optimizer.html#ecgan.utils.optimizer.BaseOptimizer.configure">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">configure</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the default configuration for an optimizer.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">BaseOptimizer</span><span class="o">.</span><span class="n">_configure</span><span class="p">(</span><span class="n">Optimizers</span><span class="o">.</span><span class="n">UNDEFINED</span><span class="o">.</span><span class="n">value</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="Adam"><a class="viewcode-back" href="../../../api/utils/optimizer.html#ecgan.utils.optimizer.Adam">[docs]</a><span class="k">class</span> <span class="nc">Adam</span><span class="p">(</span><span class="n">BaseOptimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Adam optimizer wrapper around the PyTorch implementation.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module_config</span><span class="p">,</span>
        <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">betas</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module_config</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">betas</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">betas</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">betas</span> <span class="o">=</span> <span class="n">betas</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="p">,</span>
            <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">,</span>
            <span class="n">betas</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="p">,</span>
            <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optim</span><span class="o">.</span><span class="n">param_groups</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optim</span>

<div class="viewcode-block" id="Adam.configure"><a class="viewcode-back" href="../../../api/utils/optimizer.html#ecgan.utils.optimizer.Adam.configure">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">configure</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the default configuration for the Adam optimizer.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">BaseOptimizer</span><span class="o">.</span><span class="n">_configure</span><span class="p">(</span><span class="n">Optimizers</span><span class="o">.</span><span class="n">ADAM</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
        <span class="n">config</span><span class="p">[</span><span class="s1">&#39;OPTIMIZER&#39;</span><span class="p">][</span><span class="s1">&#39;BETAS&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">config</span></div></div>


<div class="viewcode-block" id="StochasticGradientDescent"><a class="viewcode-back" href="../../../api/utils/optimizer.html#ecgan.utils.optimizer.StochasticGradientDescent">[docs]</a><span class="k">class</span> <span class="nc">StochasticGradientDescent</span><span class="p">(</span><span class="n">BaseOptimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Stochastic gradient descent optimizer. For a Momentum variant see `Momentum`.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module_config</span><span class="p">,</span> <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module_config</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">module_config</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optim</span><span class="o">.</span><span class="n">param_groups</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optim</span>

<div class="viewcode-block" id="StochasticGradientDescent.configure"><a class="viewcode-back" href="../../../api/utils/optimizer.html#ecgan.utils.optimizer.StochasticGradientDescent.configure">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">configure</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the default configuration for the Adam optimizer.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">BaseOptimizer</span><span class="o">.</span><span class="n">_configure</span><span class="p">(</span><span class="n">Optimizers</span><span class="o">.</span><span class="n">STOCHASTIC_GRADIENT_DESCENT</span><span class="o">.</span><span class="n">value</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="Momentum"><a class="viewcode-back" href="../../../api/utils/optimizer.html#ecgan.utils.optimizer.Momentum">[docs]</a><span class="k">class</span> <span class="nc">Momentum</span><span class="p">(</span><span class="n">BaseOptimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Momentum optimizer wrapper around the PyTorch implementation.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module_config</span><span class="p">,</span>
        <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
        <span class="n">dampening</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module_config</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dampening</span> <span class="o">=</span> <span class="n">dampening</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
            <span class="n">module_config</span><span class="p">,</span>
            <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">,</span>
            <span class="n">momentum</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span>
            <span class="n">dampening</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dampening</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optim</span><span class="o">.</span><span class="n">param_groups</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optim</span>

<div class="viewcode-block" id="Momentum.configure"><a class="viewcode-back" href="../../../api/utils/optimizer.html#ecgan.utils.optimizer.Momentum.configure">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">configure</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the default configuration for the Momentum optimizer.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">BaseOptimizer</span><span class="o">.</span><span class="n">_configure</span><span class="p">(</span><span class="n">Optimizers</span><span class="o">.</span><span class="n">MOMENTUM</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
        <span class="n">config</span><span class="p">[</span><span class="s1">&#39;OPTIMIZER&#39;</span><span class="p">][</span><span class="s1">&#39;MOMENTUM&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.9</span>
        <span class="n">config</span><span class="p">[</span><span class="s1">&#39;OPTIMIZER&#39;</span><span class="p">][</span><span class="s1">&#39;DAMPENING&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">return</span> <span class="n">config</span></div></div>


<div class="viewcode-block" id="RMSprop"><a class="viewcode-back" href="../../../api/utils/optimizer.html#ecgan.utils.optimizer.RMSprop">[docs]</a><span class="k">class</span> <span class="nc">RMSprop</span><span class="p">(</span><span class="n">BaseOptimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wrapper for the PyTorch RMSprop implementation.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module_config</span><span class="p">,</span>
        <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.99</span><span class="p">,</span>
        <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-08</span><span class="p">,</span>
        <span class="n">centered</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module_config</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">centered</span> <span class="o">=</span> <span class="n">centered</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">(</span>
            <span class="n">module_config</span><span class="p">,</span>
            <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">,</span>
            <span class="n">momentum</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span>
            <span class="n">centered</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">centered</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optim</span><span class="o">.</span><span class="n">param_groups</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optim</span>

<div class="viewcode-block" id="RMSprop.configure"><a class="viewcode-back" href="../../../api/utils/optimizer.html#ecgan.utils.optimizer.RMSprop.configure">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">configure</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the default configuration for a the RMSprop optimizer.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">BaseOptimizer</span><span class="o">.</span><span class="n">_configure</span><span class="p">(</span><span class="n">Optimizers</span><span class="o">.</span><span class="n">RMS_PROP</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
        <span class="n">config</span><span class="p">[</span><span class="s1">&#39;OPTIMIZER&#39;</span><span class="p">][</span><span class="s1">&#39;MOMENTUM&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.9</span>
        <span class="n">config</span><span class="p">[</span><span class="s1">&#39;OPTIMIZER&#39;</span><span class="p">][</span><span class="s1">&#39;ALPHA&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.99</span>
        <span class="n">config</span><span class="p">[</span><span class="s1">&#39;OPTIMIZER&#39;</span><span class="p">][</span><span class="s1">&#39;EPS&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-8</span>
        <span class="n">config</span><span class="p">[</span><span class="s1">&#39;OPTIMIZER&#39;</span><span class="p">][</span><span class="s1">&#39;CENTERED&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="n">config</span></div></div>


<div class="viewcode-block" id="AdaBelief"><a class="viewcode-back" href="../../../api/utils/optimizer.html#ecgan.utils.optimizer.AdaBelief">[docs]</a><span class="k">class</span> <span class="nc">AdaBelief</span><span class="p">(</span><span class="n">BaseOptimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Wrapper for the AdaBelief implementation.</span>

<span class="sd">    Not currently supported by PyTorch itself, taken from the official</span>
<span class="sd">    adabelief-pytorch repo until then.</span>
<span class="sd">    More information can be found at [Zhuang, GitHub Pages](https://juntang-zhuang.github.io/adabelief/).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module_config</span><span class="p">,</span>
        <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">betas</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-16</span><span class="p">,</span>
        <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module_config</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">betas</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">betas</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">betas</span> <span class="o">=</span> <span class="n">betas</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optim</span> <span class="o">=</span> <span class="n">AdaBeliefOptimizer</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="p">,</span>
            <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">,</span>
            <span class="n">betas</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="p">,</span>
            <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optim</span><span class="o">.</span><span class="n">param_groups</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optim</span>  <span class="c1"># type: ignore</span>

<div class="viewcode-block" id="AdaBelief.configure"><a class="viewcode-back" href="../../../api/utils/optimizer.html#ecgan.utils.optimizer.AdaBelief.configure">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">configure</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the default configuration for the Adabelief optimizer.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">BaseOptimizer</span><span class="o">.</span><span class="n">_configure</span><span class="p">(</span><span class="n">Optimizers</span><span class="o">.</span><span class="n">ADABELIEF</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
        <span class="n">config</span><span class="p">[</span><span class="s1">&#39;OPTIMIZER&#39;</span><span class="p">][</span><span class="s1">&#39;LR&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">2e-4</span>
        <span class="n">config</span><span class="p">[</span><span class="s1">&#39;OPTIMIZER&#39;</span><span class="p">][</span><span class="s1">&#39;EPS&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-16</span>
        <span class="n">config</span><span class="p">[</span><span class="s1">&#39;OPTIMIZER&#39;</span><span class="p">][</span><span class="s1">&#39;BETAS&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">config</span></div></div>


<div class="viewcode-block" id="OptimizerFactory"><a class="viewcode-back" href="../../../api/utils/optimizer.html#ecgan.utils.optimizer.OptimizerFactory">[docs]</a><span class="k">class</span> <span class="nc">OptimizerFactory</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Meta module for creating an optimizer instance.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module_config</span><span class="p">,</span> <span class="n">optim_cfg</span><span class="p">:</span> <span class="n">OptimizerConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BaseOptimizer</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return an instance of an optimizer.&quot;&quot;&quot;</span>
        <span class="n">optimizer</span><span class="p">:</span> <span class="n">Optimizers</span> <span class="o">=</span> <span class="n">Optimizers</span><span class="p">(</span><span class="n">optim_cfg</span><span class="o">.</span><span class="n">NAME</span><span class="p">)</span>
        <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">get_</span><span class="p">(</span><span class="n">optim_cfg</span><span class="o">.</span><span class="n">LR</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">))</span>
        <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">get_</span><span class="p">(</span><span class="n">optim_cfg</span><span class="o">.</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="n">Optimizers</span><span class="o">.</span><span class="n">STOCHASTIC_GRADIENT_DESCENT</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">StochasticGradientDescent</span><span class="p">(</span><span class="n">module_config</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="n">Optimizers</span><span class="o">.</span><span class="n">MOMENTUM</span><span class="p">:</span>
            <span class="n">momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">get_</span><span class="p">(</span><span class="n">optim_cfg</span><span class="o">.</span><span class="n">MOMENTUM</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
            <span class="n">dampening</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">get_</span><span class="p">(</span><span class="n">optim_cfg</span><span class="o">.</span><span class="n">DAMPENING</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">Momentum</span><span class="p">(</span>
                <span class="n">module_config</span><span class="p">,</span>
                <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
                <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
                <span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">,</span>
                <span class="n">dampening</span><span class="o">=</span><span class="n">dampening</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="n">Optimizers</span><span class="o">.</span><span class="n">ADAM</span><span class="p">:</span>
            <span class="n">betas</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">get_</span><span class="p">(</span><span class="n">optim_cfg</span><span class="o">.</span><span class="n">BETAS</span><span class="p">,</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">))</span>
            <span class="n">adam_eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">get_</span><span class="p">(</span><span class="n">optim_cfg</span><span class="o">.</span><span class="n">EPS</span><span class="p">,</span> <span class="mf">1e-8</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">Adam</span><span class="p">(</span>
                <span class="n">module_config</span><span class="p">,</span>
                <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
                <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
                <span class="n">betas</span><span class="o">=</span><span class="n">betas</span><span class="p">,</span>
                <span class="n">eps</span><span class="o">=</span><span class="n">adam_eps</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="n">Optimizers</span><span class="o">.</span><span class="n">RMS_PROP</span><span class="p">:</span>
            <span class="n">rms_momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">get_</span><span class="p">(</span><span class="n">optim_cfg</span><span class="o">.</span><span class="n">MOMENTUM</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
            <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">get_</span><span class="p">(</span><span class="n">optim_cfg</span><span class="o">.</span><span class="n">ALPHA</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">)</span>
            <span class="n">rms_eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">get_</span><span class="p">(</span><span class="n">optim_cfg</span><span class="o">.</span><span class="n">EPS</span><span class="p">,</span> <span class="mf">1e-8</span><span class="p">)</span>
            <span class="n">centered</span> <span class="o">=</span> <span class="n">get_</span><span class="p">(</span><span class="n">optim_cfg</span><span class="o">.</span><span class="n">CENTERED</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">RMSprop</span><span class="p">(</span>
                <span class="n">module_config</span><span class="p">,</span>
                <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
                <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
                <span class="n">momentum</span><span class="o">=</span><span class="n">rms_momentum</span><span class="p">,</span>
                <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span>
                <span class="n">eps</span><span class="o">=</span><span class="n">rms_eps</span><span class="p">,</span>
                <span class="n">centered</span><span class="o">=</span><span class="n">centered</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="n">Optimizers</span><span class="o">.</span><span class="n">ADABELIEF</span><span class="p">:</span>
            <span class="n">adabelief_betas</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">get_</span><span class="p">(</span><span class="n">optim_cfg</span><span class="o">.</span><span class="n">BETAS</span><span class="p">,</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">))</span>
            <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">get_</span><span class="p">(</span><span class="n">optim_cfg</span><span class="o">.</span><span class="n">EPS</span><span class="p">,</span> <span class="mf">1e-16</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">AdaBelief</span><span class="p">(</span>
                <span class="n">module_config</span><span class="p">,</span>
                <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
                <span class="n">betas</span><span class="o">=</span><span class="n">adabelief_betas</span><span class="p">,</span>
                <span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span>
                <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s1">&#39;Argument </span><span class="si">{0}</span><span class="s1"> is not set correctly.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">optimizer</span><span class="p">))</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Fiete Ler, Tobias Weber, Maxim Dolgich.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>